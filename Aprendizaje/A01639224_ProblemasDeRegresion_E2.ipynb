{"cells":[{"cell_type":"markdown","metadata":{"id":"-zx999QwJzep"},"source":["<h1>Problemas de regresión - Ejercicio 2</h1>\n","\n","A01639224 | Fausto Alejandro Palma Cervantes\n","\n","TC3006C.102 | Inteligencia artificial avanzada para la ciencia de datos I\n","\n","28 de agosto de 2023"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4v4f0JDHVBJV"},"outputs":[],"source":["# Importar librerías y módulos\n","import pandas as pd\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import cross_validate, KFold\n","import numpy as np\n","from sklearn.feature_selection import SelectKBest, r_regression, SequentialFeatureSelector, RFE\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.model_selection import ShuffleSplit\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"cU-hrk2D7Wh8"},"source":["# Ejercicio 2\n","\n","**2 - Todas las variables, menos X2, X6, X10, X14, X18**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":168,"status":"ok","timestamp":1693566874459,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"TFR0JEpZ7KKK","colab":{"base_uri":"https://localhost:8080/","height":308},"outputId":"20df2b4b-1da2-442b-8532-fc4b3f842baa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Country  Year      Status  Life expectancy   Adult Mortality  \\\n","0  Afghanistan  2015  Developing              65.0            263.0   \n","1  Afghanistan  2014  Developing              59.9            271.0   \n","2  Afghanistan  2013  Developing              59.9            268.0   \n","3  Afghanistan  2012  Developing              59.5            272.0   \n","4  Afghanistan  2011  Developing              59.2            275.0   \n","\n","   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n","0             62     0.01               71.279624         65.0      1154  ...   \n","1             64     0.01               73.523582         62.0       492  ...   \n","2             66     0.01               73.219243         64.0       430  ...   \n","3             69     0.01               78.184215         67.0      2787  ...   \n","4             71     0.01                7.097109         68.0      3013  ...   \n","\n","   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n","0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n","1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n","2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n","3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n","4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n","\n","    thinness  1-19 years   thinness 5-9 years  \\\n","0                   17.2                 17.3   \n","1                   17.5                 17.5   \n","2                   17.7                 17.7   \n","3                   17.9                 18.0   \n","4                   18.2                 18.2   \n","\n","   Income composition of resources  Schooling  \n","0                            0.479       10.1  \n","1                            0.476       10.0  \n","2                            0.470        9.9  \n","3                            0.463        9.8  \n","4                            0.454        9.5  \n","\n","[5 rows x 22 columns]"],"text/html":["\n","  <div id=\"df-d53a0059-1dd7-4b08-b519-0e11a093c538\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Country</th>\n","      <th>Year</th>\n","      <th>Status</th>\n","      <th>Life expectancy</th>\n","      <th>Adult Mortality</th>\n","      <th>infant deaths</th>\n","      <th>Alcohol</th>\n","      <th>percentage expenditure</th>\n","      <th>Hepatitis B</th>\n","      <th>Measles</th>\n","      <th>...</th>\n","      <th>Polio</th>\n","      <th>Total expenditure</th>\n","      <th>Diphtheria</th>\n","      <th>HIV/AIDS</th>\n","      <th>GDP</th>\n","      <th>Population</th>\n","      <th>thinness  1-19 years</th>\n","      <th>thinness 5-9 years</th>\n","      <th>Income composition of resources</th>\n","      <th>Schooling</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Afghanistan</td>\n","      <td>2015</td>\n","      <td>Developing</td>\n","      <td>65.0</td>\n","      <td>263.0</td>\n","      <td>62</td>\n","      <td>0.01</td>\n","      <td>71.279624</td>\n","      <td>65.0</td>\n","      <td>1154</td>\n","      <td>...</td>\n","      <td>6.0</td>\n","      <td>8.16</td>\n","      <td>65.0</td>\n","      <td>0.1</td>\n","      <td>584.259210</td>\n","      <td>33736494.0</td>\n","      <td>17.2</td>\n","      <td>17.3</td>\n","      <td>0.479</td>\n","      <td>10.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Afghanistan</td>\n","      <td>2014</td>\n","      <td>Developing</td>\n","      <td>59.9</td>\n","      <td>271.0</td>\n","      <td>64</td>\n","      <td>0.01</td>\n","      <td>73.523582</td>\n","      <td>62.0</td>\n","      <td>492</td>\n","      <td>...</td>\n","      <td>58.0</td>\n","      <td>8.18</td>\n","      <td>62.0</td>\n","      <td>0.1</td>\n","      <td>612.696514</td>\n","      <td>327582.0</td>\n","      <td>17.5</td>\n","      <td>17.5</td>\n","      <td>0.476</td>\n","      <td>10.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Afghanistan</td>\n","      <td>2013</td>\n","      <td>Developing</td>\n","      <td>59.9</td>\n","      <td>268.0</td>\n","      <td>66</td>\n","      <td>0.01</td>\n","      <td>73.219243</td>\n","      <td>64.0</td>\n","      <td>430</td>\n","      <td>...</td>\n","      <td>62.0</td>\n","      <td>8.13</td>\n","      <td>64.0</td>\n","      <td>0.1</td>\n","      <td>631.744976</td>\n","      <td>31731688.0</td>\n","      <td>17.7</td>\n","      <td>17.7</td>\n","      <td>0.470</td>\n","      <td>9.9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Afghanistan</td>\n","      <td>2012</td>\n","      <td>Developing</td>\n","      <td>59.5</td>\n","      <td>272.0</td>\n","      <td>69</td>\n","      <td>0.01</td>\n","      <td>78.184215</td>\n","      <td>67.0</td>\n","      <td>2787</td>\n","      <td>...</td>\n","      <td>67.0</td>\n","      <td>8.52</td>\n","      <td>67.0</td>\n","      <td>0.1</td>\n","      <td>669.959000</td>\n","      <td>3696958.0</td>\n","      <td>17.9</td>\n","      <td>18.0</td>\n","      <td>0.463</td>\n","      <td>9.8</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Afghanistan</td>\n","      <td>2011</td>\n","      <td>Developing</td>\n","      <td>59.2</td>\n","      <td>275.0</td>\n","      <td>71</td>\n","      <td>0.01</td>\n","      <td>7.097109</td>\n","      <td>68.0</td>\n","      <td>3013</td>\n","      <td>...</td>\n","      <td>68.0</td>\n","      <td>7.87</td>\n","      <td>68.0</td>\n","      <td>0.1</td>\n","      <td>63.537231</td>\n","      <td>2978599.0</td>\n","      <td>18.2</td>\n","      <td>18.2</td>\n","      <td>0.454</td>\n","      <td>9.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 22 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d53a0059-1dd7-4b08-b519-0e11a093c538')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d53a0059-1dd7-4b08-b519-0e11a093c538 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d53a0059-1dd7-4b08-b519-0e11a093c538');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f0d2d10e-9ab3-495f-b9df-1116755658f8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0d2d10e-9ab3-495f-b9df-1116755658f8')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f0d2d10e-9ab3-495f-b9df-1116755658f8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":23}],"source":["# Importar el conjunto de datos\n","led_df = pd.read_csv('/content/drive/MyDrive/z. Aprendizaje/Life Expectancy Data.csv')\n","led_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":355,"status":"ok","timestamp":1693566254071,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"BVUOkgHZC1VV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28577f2b-a3a0-446e-b2e7-30d605c5c587"},"outputs":[{"output_type":"stream","name":"stdout","text":["Coeficientes del modelo:  [-1.96994569e-02  3.45870007e-02  2.44581955e-04 -5.27410042e-03\n","  5.50687685e-02 -2.59113222e-03  1.74407273e-02  2.34737374e-02\n"," -4.32085448e-01  5.05043308e-05 -6.25244236e-02  1.05458390e-02\n","  1.69019221e+01]\n","Intercepto del modelo:  57.44131799006827\n","MSE:  18.148492188328156\n","MAE:  3.1255409417300255\n","R^2:  0.7014577963224626\n"]}],"source":["# 1. Evalúa con validación cruzada un modelo de regresión lineal para las variables\n","# asignadas según tu matrícula utilizando alguna librería o framework.\n","\n","# Eliminar registros con valores nulos\n","led_df.dropna(inplace=True)\n","\n","# Matriz de las variables predictoras\n","x = led_df.drop(['Country', 'Year',\t'Status', 'Life expectancy ', 'infant deaths', 'Measles ', 'Total expenditure', 'Population', 'Schooling'], axis=1).to_numpy()\n","\n","# Arreglo de la variable de respuesta\n","y = led_df['Life expectancy '].to_numpy()\n","\n","# Creación del modelo\n","model = LinearRegression()\n","\n","# Ajuste del modelo\n","model.fit(x, y)\n","\n","# Impresión de resultados\n","print(\"Coeficientes del modelo: \", model.coef_)\n","print(\"Intercepto del modelo: \", model.intercept_)\n","\n","# Calcular métricas MSE, MAE y R^2 con cross_validate\n","scoring = {\n","    'mse': make_scorer(mean_squared_error),\n","    'mae': make_scorer(mean_absolute_error),\n","    'r2': make_scorer(r2_score)\n","}\n","\n","# Realizar validación cruzada\n","results = cross_validate(model, x, y, cv=17, scoring=scoring)\n","# cv : plieges, scoring : métricas\n","\n","# Calcular y mostrar promedio de cada métrica\n","print('MSE: ', np.mean(results[\"test_mse\"]))\n","print(\"MAE: \", np.mean(results[\"test_mae\"]))\n","print(\"R^2: \", np.mean(results[\"test_r2\"]))"]},{"cell_type":"code","source":["# 2. Encuentra el número óptimo de predictores para el modelo utilizando el método filter y validación cruzada.\n","# Una vez que tengas el número óptimo, muestra las características seleccionadas.\n","\n","# Definir el número de características\n","n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","\n","# Arreglo para guardar los valores para cada número de características\n","mse_nfeat = []\n","mae_nfeat = []\n","r2_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    mse_cv = []\n","    mae_cv = []\n","    r2_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = KFold(n_splits=17, shuffle = True)\n","    # n_splits : número de plieges\n","\n","    for train_index, test_index in kf.split(x):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        regr_cv = LinearRegression()\n","        fselection_cv = SelectKBest(r_regression, k = n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        regr_cv.fit(x_train, y_train)\n","\n","        # Probar el modelo con el conjunto de prueba\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = regr_cv.predict(x_test)\n","\n","        # Calcular los valores de MSE, MAE y R^2 y añadir a sus respectivos arreglos\n","        mse_i = mean_squared_error(y_test, y_pred)\n","        mse_cv.append(mse_i)\n","        mae_i = mean_absolute_error(y_test, y_pred)\n","        mae_cv.append(mae_i)\n","        r2_i = r2_score(y_test, y_pred)\n","        r2_cv.append(r2_i)\n","\n","    # Calcular los valores de MSE, MAE y R^2 para cada cada número de características\n","    mse = np.average(mse_cv)\n","    mse_nfeat.append(mse)\n","    mae = np.average(mae_cv)\n","    mae_nfeat.append(mae)\n","    r2 = np.average(r2_cv)\n","    r2_nfeat.append(r2)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, ' | MSE:', mse, '  MAE:', mae,'  R^2:', r2)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmin(mse_nfeat)\n","opt_features = n_feats[opt_index]\n","print(\"Número óptimo de predictores: \", opt_features)\n","\n","# Seleccionar el número óptimo de predictores\n","regr = LinearRegression()\n","fselection = SelectKBest(r_regression, k = opt_features)\n","fselection.fit(x, y)\n","print(\"Predictores óptimos: \", fselection.get_feature_names_out())\n","\n","# Calcular un modelo con los predictores óptimos\n","x_transformed = fselection.transform(x)\n","regr.fit(x_transformed, y)\n","print(\"Coeficientes del modelo: \", model.coef_)\n","print(\"Intercepto del modelo: \", model.intercept_)"],"metadata":{"id":"gMUmRf05UO33","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693564474267,"user_tz":360,"elapsed":3831,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"a0659651-2402-4f7e-94f6-0aa3dc216627"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["N: 1  | MSE: 37.30430826415641   MAE: 4.242541880671888   R^2: 0.5164354259229741\n","N: 2  | MSE: 34.190002159665056   MAE: 4.161011709548528   R^2: 0.554366339461457\n","N: 3  | MSE: 33.13284847146791   MAE: 4.148588817323639   R^2: 0.5653466593067844\n","N: 4  | MSE: 33.179030820720904   MAE: 4.151783702741383   R^2: 0.5591501478353087\n","N: 5  | MSE: 33.012763926993166   MAE: 4.124716554449351   R^2: 0.5603410527158852\n","N: 6  | MSE: 32.13459477066927   MAE: 4.073293995675175   R^2: 0.5814290109448998\n","N: 7  | MSE: 31.939361334535285   MAE: 4.0551020611035105   R^2: 0.5820384382536796\n","N: 8  | MSE: 31.872188042503574   MAE: 4.050940313729059   R^2: 0.5841058839869271\n","N: 9  | MSE: 31.956980689076463   MAE: 4.071410641142577   R^2: 0.5746089866951419\n","N: 10  | MSE: 31.56995623010626   MAE: 4.053581689848859   R^2: 0.5839769705927144\n","N: 11  | MSE: 31.885374918756128   MAE: 4.072980880851725   R^2: 0.5811758268587122\n","N: 12  | MSE: 19.196032484472852   MAE: 3.325016409303016   R^2: 0.7483402881589442\n","N: 13  | MSE: 15.66327255448784   MAE: 2.9481774779287724   R^2: 0.792755265613674\n","Número óptimo de predictores:  13\n","Predictores óptimos:  ['x0' 'x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x11' 'x12']\n","Coeficientes del modelo:  [-1.96994569e-02  3.45870007e-02  2.44581955e-04 -5.27410042e-03\n","  5.50687685e-02 -2.59113222e-03  1.74407273e-02  2.34737374e-02\n"," -4.32085448e-01  5.05043308e-05 -6.25244236e-02  1.05458390e-02\n","  1.69019221e+01]\n","Intercepto del modelo:  57.44131799006827\n"]}]},{"cell_type":"code","source":["# 3. Repite el paso anterior pero con selección de características secuencial (Wrapper).\n","# Reporta los predictores óptimos encontrados por el método.\n","\n","# Definir el número de características\n","n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n","\n","# Arreglo para guardar los valores para cada número de características\n","mse_nfeat = []\n","mae_nfeat = []\n","r2_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    mse_cv = []\n","    mae_cv = []\n","    r2_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = KFold(n_splits=17, shuffle = True)\n","    # n_splits : número de plieges\n","\n","    for train_index, test_index in kf.split(x):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        regr_cv = LinearRegression()\n","        fselection_cv = SequentialFeatureSelector(regr_cv, n_features_to_select=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        regr_cv.fit(x_train, y_train)\n","\n","        # Test phase\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = regr_cv.predict(x_test)\n","\n","        # Calcular los valores de MSE, MAE y R^2 y añadir a sus respectivos arreglos\n","        mse_i = mean_squared_error(y_test, y_pred)\n","        mse_cv.append(mse_i)\n","        mae_i = mean_absolute_error(y_test, y_pred)\n","        mae_cv.append(mae_i)\n","        r2_i = r2_score(y_test, y_pred)\n","        r2_cv.append(r2_i)\n","\n","    # Calcular los valores de MSE, MAE y R^2 para cada cada número de características\n","    mse = np.average(mse_cv)\n","    mse_nfeat.append(mse)\n","    mae = np.average(mae_cv)\n","    mae_nfeat.append(mae)\n","    r2 = np.average(r2_cv)\n","    r2_nfeat.append(r2)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, ' | MSE:', mse, '  MAE:', mae,'  R^2:', r2)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmin(mse_nfeat)\n","opt_features = n_feats[opt_index]\n","print(\"Número óptimo de predictores: \", opt_features)\n","\n","# Seleccionar el número óptimo de predictores\n","regr = LinearRegression()\n","fselection = SequentialFeatureSelector(regr, n_features_to_select = opt_features)\n","fselection.fit(x, y)\n","print(\"Predictores óptimos: \", fselection.get_feature_names_out())\n","\n","# Calcular un modelo con los predictores óptimos\n","x_transformed = fselection.transform(x)\n","regr.fit(x_transformed, y)\n","print(\"Coeficientes del modelo: \", model.coef_)\n","print(\"Intercepto del modelo: \", model.intercept_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":250},"id":"QHf6ZlkTBgbU","executionInfo":{"status":"error","timestamp":1694064151157,"user_tz":360,"elapsed":517,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"908b0145-63b1-4686-df6f-715fca2c3926"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-081332a60fe6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Dividir los conjuntos de prueba y entrenamiento\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;31m# n_splits : número de plieges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'KFold' is not defined"]}]},{"cell_type":"code","source":["# 4. Haz el mismo proceso del paso 2, pero ahora con el método de selección de características recursivo (Filter-Wrapper).\n","# Reporta los predictores óptimos encontrados por el método.\n","\n","# Definir el número de características\n","n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","\n","# Arreglo para guardar los valores para cada número de características\n","mse_nfeat = []\n","mae_nfeat = []\n","r2_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    mse_cv = []\n","    mae_cv = []\n","    r2_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = KFold(n_splits=17, shuffle = True)\n","    # n_splits : número de plieges\n","\n","    for train_index, test_index in kf.split(x):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        regr_cv = LinearRegression()\n","        fselection_cv = RFE(regr_cv, n_features_to_select=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        regr_cv.fit(x_train, y_train)\n","\n","        # Test phase\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = regr_cv.predict(x_test)\n","\n","        # Calcular los valores de MSE, MAE y R^2 y añadir a sus respectivos arreglos\n","        mse_i = mean_squared_error(y_test, y_pred)\n","        mse_cv.append(mse_i)\n","        mae_i = mean_absolute_error(y_test, y_pred)\n","        mae_cv.append(mae_i)\n","        r2_i = r2_score(y_test, y_pred)\n","        r2_cv.append(r2_i)\n","\n","    # Calcular los valores de MSE, MAE y R^2 para cada cada número de características\n","    mse = np.average(mse_cv)\n","    mse_nfeat.append(mse)\n","    mae = np.average(mae_cv)\n","    mae_nfeat.append(mae)\n","    r2 = np.average(r2_cv)\n","    r2_nfeat.append(r2)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, ' | MSE:', mse, '  MAE:', mae,'  R^2:', r2)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmin(mse_nfeat)\n","opt_features = n_feats[opt_index]\n","print(\"Número óptimo de predictores: \", opt_features)\n","\n","# Seleccionar el número óptimo de predictores\n","regr = LinearRegression()\n","fselection = RFE(regr, n_features_to_select = opt_features)\n","fselection.fit(x, y)\n","print(\"Predictores óptimos: \", fselection.get_feature_names_out())\n","\n","# Calcular un modelo con los predictores óptimos\n","x_transformed = fselection.transform(x)\n","regr.fit(x_transformed, y)\n","print(\"Coeficientes del modelo: \", model.coef_)\n","print(\"Intercepto del modelo: \", model.intercept_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pT3SNyzdGDkv","executionInfo":{"status":"ok","timestamp":1693564633368,"user_tz":360,"elapsed":5664,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"2c4b4cea-fc01-4276-f4bc-b0ee5a258bf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["N: 1  | MSE: 37.36551154704997   MAE: 4.249755216690785   R^2: 0.5035583952304861\n","N: 2  | MSE: 23.25454770823098   MAE: 3.534025849724838   R^2: 0.693632538331727\n","N: 3  | MSE: 22.319516941822844   MAE: 3.5098672125917028   R^2: 0.7038027506443016\n","N: 4  | MSE: 22.036334974126124   MAE: 3.4995594607629066   R^2: 0.7111991255493069\n","N: 5  | MSE: 21.086102993359106   MAE: 3.4220309508802096   R^2: 0.7224457454768187\n","N: 6  | MSE: 20.840063106804372   MAE: 3.419071801120718   R^2: 0.7267938019207153\n","N: 7  | MSE: 19.640218421031502   MAE: 3.295943771398242   R^2: 0.7384223254593626\n","N: 8  | MSE: 16.64586534993232   MAE: 2.998935997810483   R^2: 0.777528972036757\n","N: 9  | MSE: 16.63256938660793   MAE: 2.993307724822673   R^2: 0.7810358442289038\n","N: 10  | MSE: 16.575172870089656   MAE: 2.9924008164079177   R^2: 0.7760967678165027\n","N: 11  | MSE: 16.46143431882318   MAE: 2.996808656023012   R^2: 0.7840956045412832\n","N: 12  | MSE: 15.760814406690042   MAE: 2.95746671907676   R^2: 0.7920726875491867\n","N: 13  | MSE: 15.72865691519992   MAE: 2.954843081047929   R^2: 0.7925373866069582\n","Número óptimo de predictores:  13\n","Predictores óptimos:  ['x0' 'x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x11' 'x12']\n","Coeficientes del modelo:  [-1.96994569e-02  3.45870007e-02  2.44581955e-04 -5.27410042e-03\n","  5.50687685e-02 -2.59113222e-03  1.74407273e-02  2.34737374e-02\n"," -4.32085448e-01  5.05043308e-05 -6.25244236e-02  1.05458390e-02\n","  1.69019221e+01]\n","Intercepto del modelo:  57.44131799006827\n"]}]},{"cell_type":"code","source":["# 5. Repita los pasos anteriores, pero utilizando un modelo de regresión no lineal como K-vecinos más cercanos.\n","# \"Para un modelo no lineal, R^2 no tiene sentido alguno\"\n","\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","# Creación del modelo\n","model = KNeighborsRegressor(n_neighbors = 10)\n","\n","# Ajuste del modelo\n","model.fit(x, y)\n","\n","# Impresión de resultados\n","\n","# Calcular métricas MSE, MAE y R^2 con cross_validate\n","scoring = {\n","    'mse': make_scorer(mean_squared_error),\n","    'mae': make_scorer(mean_absolute_error),\n","}\n","\n","# Realizar validación cruzada\n","results = cross_validate(model, x, y, cv=17, scoring=scoring)\n","\n","# Calcular y mostrar promedio de cada métrica\n","print('MSE: ', np.mean(results[\"test_mse\"]))\n","print(\"MAE: \", np.mean(results[\"test_mae\"]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ZGuDr0jICt8","executionInfo":{"status":"ok","timestamp":1693564633576,"user_tz":360,"elapsed":229,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"b0dec8bf-2e4a-4eb9-d320-6074aaca9132"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  23.868732807762278\n","MAE:  3.4769557307459067\n"]}]},{"cell_type":"code","source":["# FILTER\n","\n","# Definir el número de características\n","n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n","\n","# Arreglo para guardar los valores para cada número de características\n","mse_nfeat = []\n","mae_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    mse_cv = []\n","    mae_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = KFold(n_splits=17, shuffle = True)\n","    # n_splits : número de plieges\n","\n","    for train_index, test_index in kf.split(x):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        regr_cv = KNeighborsRegressor(n_neighbors = 10)\n","        fselection_cv = SelectKBest(r_regression, k = n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        regr_cv.fit(x_train, y_train)\n","\n","        # Probar el modelo con el conjunto de prueba\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = regr_cv.predict(x_test)\n","\n","        # Calcular los valores de MSE, MAE y R^2 y añadir a sus respectivos arreglos\n","        mse_i = mean_squared_error(y_test, y_pred)\n","        mse_cv.append(mse_i)\n","        mae_i = mean_absolute_error(y_test, y_pred)\n","        mae_cv.append(mae_i)\n","\n","    # Calcular los valores de MSE, MAE y R^2 para cada cada número de características\n","    mse = np.average(mse_cv)\n","    mse_nfeat.append(mse)\n","    mae = np.average(mae_cv)\n","    mae_nfeat.append(mae)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, ' | MSE:', mse, '  MAE:', mae)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmin(mse_nfeat)\n","opt_features = n_feats[opt_index]\n","print(\"Número óptimo de predictores: \", opt_features)\n","\n","# Seleccionar el número óptimo de predictores\n","regr = KNeighborsRegressor(n_neighbors = 10)\n","fselection = SelectKBest(r_regression, k = opt_features)\n","fselection.fit(x, y)\n","print(\"Predictores óptimos: \", fselection.get_feature_names_out())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yWrQbur1KP8a","executionInfo":{"status":"ok","timestamp":1693564636181,"user_tz":360,"elapsed":2623,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"520f5094-8c6b-4036-f823-ced5e1603952"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["N: 1  | MSE: 21.739477137659186   MAE: 3.4608489993935723\n","N: 2  | MSE: 33.313908489993935   MAE: 4.416876895087932\n","N: 3  | MSE: 42.77377919951486   MAE: 4.8287143723468775\n","N: 4  | MSE: 43.38181255306247   MAE: 4.92146149181322\n","N: 5  | MSE: 44.06877550030322   MAE: 4.97262583383869\n","N: 6  | MSE: 42.386709157064885   MAE: 4.856337174044875\n","N: 7  | MSE: 42.49139144936325   MAE: 4.882844147968465\n","N: 8  | MSE: 43.087139599757435   MAE: 4.89454214675561\n","N: 9  | MSE: 39.22546561552456   MAE: 4.601152213462704\n","N: 10  | MSE: 39.42612201334142   MAE: 4.627180109157066\n","N: 11  | MSE: 39.541152698605224   MAE: 4.646137052759249\n","N: 12  | MSE: 37.970220982413586   MAE: 4.546610066707096\n","N: 13  | MSE: 20.066991934505765   MAE: 3.1697210430563976\n","Número óptimo de predictores:  13\n","Predictores óptimos:  ['x0' 'x1' 'x2' 'x3' 'x4' 'x5' 'x6' 'x7' 'x8' 'x9' 'x10' 'x11' 'x12']\n"]}]},{"cell_type":"code","source":["# WRAPPER\n","\n","# Definir el número de características\n","n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n","\n","# Arreglo para guardar los valores para cada número de características\n","mse_nfeat = []\n","mae_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    mse_cv = []\n","    mae_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = KFold(n_splits=17, shuffle = True)\n","\n","    for train_index, test_index in kf.split(x):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        regr_cv = KNeighborsRegressor(n_neighbors = 10)\n","        fselection_cv = SequentialFeatureSelector(regr_cv, n_features_to_select=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        regr_cv.fit(x_train, y_train)\n","\n","        # Test phase\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = regr_cv.predict(x_test)\n","\n","        # Calcular los valores de MSE, MAE y R^2 y añadir a sus respectivos arreglos\n","        mse_i = mean_squared_error(y_test, y_pred)\n","        mse_cv.append(mse_i)\n","        mae_i = mean_absolute_error(y_test, y_pred)\n","        mae_cv.append(mae_i)\n","\n","    # Calcular los valores de MSE, MAE y R^2 para cada cada número de características\n","    mse = np.average(mse_cv)\n","    mse_nfeat.append(mse)\n","    mae = np.average(mae_cv)\n","    mae_nfeat.append(mae)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, ' | MSE:', mse, '  MAE:', mae)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmin(mse_nfeat)\n","opt_features = n_feats[opt_index]\n","print(\"Número óptimo de predictores: \", opt_features)\n","\n","# Seleccionar el número óptimo de predictores\n","regr = KNeighborsRegressor(n_neighbors = 10)\n","fselection = SequentialFeatureSelector(regr, n_features_to_select = opt_features)\n","fselection.fit(x, y)\n","print(\"Predictores óptimos: \", fselection.get_feature_names_out())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ov2BBAJOKyA4","executionInfo":{"status":"ok","timestamp":1693564844267,"user_tz":360,"elapsed":208104,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"739dfa5a-fd21-4a2f-bcae-8cd2c2025be5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["N: 1  | MSE: 17.152851728320197   MAE: 2.5977380230442693\n","N: 2  | MSE: 10.386366646452396   MAE: 2.2689630078835656\n","N: 3  | MSE: 7.574401394784718   MAE: 1.952595512431777\n","N: 4  | MSE: 7.618319223771985   MAE: 1.8552456033959976\n","N: 5  | MSE: 6.899679805942997   MAE: 1.7991146149181323\n","N: 6  | MSE: 6.979426682838084   MAE: 1.7962765312310491\n","N: 7  | MSE: 6.828868647665253   MAE: 1.7513038204972713\n","N: 8  | MSE: 7.477462886597938   MAE: 1.8118920557913887\n","N: 9  | MSE: 8.433902789569437   MAE: 1.9184536082474228\n","N: 10  | MSE: 9.047544815039416   MAE: 1.9751970891449364\n","N: 11  | MSE: 11.326970648878106   MAE: 2.338241358399029\n","N: 12  | MSE: 11.115406852637966   MAE: 2.29310491206792\n","Número óptimo de predictores:  7\n","Predictores óptimos:  ['x0' 'x1' 'x4' 'x8' 'x10' 'x11' 'x12']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":562,"status":"ok","timestamp":1693565032461,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"83-Zx1MUS6DN","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ee835f8c-cb45-4412-a665-92e8a1ca9e8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  12.656925409338994\n","MAE:  2.5668283808368706\n"]}],"source":["# 6. Agregue la variables \"Status\" (segunda columna) como variable predictora, y utiliza un\n","# árbol de decisión para generar un modelo de regresión para la varible Life expectancy\".\n","# Evalúa este modelo con validación cruzada utilizando la métrica adecuada.\n","\n","x = led_df.drop(['Country', 'Year', 'Life expectancy ', 'infant deaths', 'Measles ', 'Total expenditure', 'Population', 'Schooling'], axis=1)\n","#.to_numpy()\n","x\n","\n","# Eliminar registros con valores nulos\n","led_df.dropna(inplace=True)\n","\n","# Matriz de las variables predictoras\n","x = led_df.drop(['Country', 'Year',\t'Status', 'Life expectancy ', 'infant deaths', 'Measles ', 'Total expenditure', 'Population', 'Schooling'], axis=1).to_numpy()\n","\n","# Arreglo de la variable de respuesta\n","y = led_df['Life expectancy '].to_numpy()\n","\n","# Creación del modelo\n","model = DecisionTreeRegressor()\n","\n","# Ajuste del modelo\n","model.fit(x, y)\n","\n","# Calcular métricas MSE, MAE y R^2 con cross_validate\n","scoring = {\n","    'mse': make_scorer(mean_squared_error),\n","    'mae': make_scorer(mean_absolute_error),\n","}\n","\n","# Realizar validación cruzada\n","results = cross_validate(model, x, y, cv=17, scoring=scoring)\n","\n","# Calcular y mostrar promedio de cada métrica\n","print('MSE: ', np.mean(results[\"test_mse\"]))\n","print(\"MAE: \", np.mean(results[\"test_mae\"]))"]},{"cell_type":"code","source":["# Dividir los conjuntos de prueba y entrenamiento aleatoriamente\n","kf = ShuffleSplit(n_splits=1000, test_size = 0.2)\n","\n","# Arreglo para guardar los valores de las pruebas\n","mse_cv = []\n","mae_cv = []\n","\n","# Repetir el proceso por cada división\n","for train_index, test_index in kf.split(x):\n","\n","    # Crear una regresión lineal con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    model.fit(x_train, y_train)\n","\n","    # Probar la regresión lineal con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = model.predict(x_test)\n","\n","    # Calcular los valores de MSE, MAE y añadir a sus respectivos arreglos\n","    mse_i = mean_squared_error(y_test, y_pred)\n","    mse_cv.append(mse_i)\n","    mae_i = mean_absolute_error(y_test, y_pred)\n","    mae_cv.append(mae_i)\n","\n","# Imprimir los resultados\n","print('MSE: ', np.average(mse_cv))\n","print(\"MAE: \", np.average(mae_cv))\n","\n","# Crear una figura y diseño para mostrar los histogramas de MSE y MAE.\n","fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n","\n","# Grafiar histograma de MSE\n","axs[0].hist(mse_cv, bins=20)\n","axs[0].set_xlabel(\"MSE\")\n","\n","# Grafiar histograma de MAE\n","axs[1].hist(mae_cv, bins=20)\n","axs[1].set_xlabel(\"MAE\")\n","\n","# Mostrar figura\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":523},"id":"h6c6bFo3SO-d","executionInfo":{"status":"ok","timestamp":1693565054276,"user_tz":360,"elapsed":18502,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"48d4ec14-038a-4810-f5f8-52f187c54f52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MSE:  6.537859181818182\n","MAE:  1.5186451515151516\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["###7. Viendo los resultados de este ejercicio, escriba una conclusión sobre los siguientes puntos:\n","\n","**1. Consideras que el modelo de regresión lineal es adecuado para los datos. ¿Por qué?**\n","\n","Considerando los valores de MSE, MAE y R^2 (18.14, 3.12 y 0.70 respectivamente) y ya que el modelo no lineal generó peores resultados al hacer la validación cruzada, el modelo de regresión lineal podría calificarse como adecuado para los datos. Sin embargo, a falta de experimentación, no es posible asegurar que no exista otro modelo más adecuado.\n","\n","**2. ¿Qué método de selección de características consideras que funciona bien con los datos? ¿Por qué?**\n","\n","Considerando que se utilizó el MSE para la selección de características, creo que el método Wrapper funciona bien con los datos. Suponiendo que el propopósito de la selección de características es disminuir el número de variables predictoras, dicho método fue el único que en varios intentos disminuyó el número de variables predictoras. En general los valores de MSE, MAE y R^2 se mantuvieron relativamente similares en los modelos finales.\n","\n","**3. Del proceso de selección de características, ¿puedes identificar algunas que sean sobresalientes? ¿Qué información relevantes observas de dichas características?**\n","\n","Al comparar los procesos de selección de características finales, hubo cuatro que se mantuvieron constantes en todos los modelos: Adult Mortality, BMI, Thinness 1-19 years e Income composition of resources. Pese a que se puede argumentar la importancia de cada una de las variables predictoras de los modelos, estas variables en su mayoría tienen que ver con la salud de las personas. Además, la disponibilidad de recursos muchas veces llega a determinar la salud a largo plazo de los individuos, especialmente previo a la adultez.\n","\n","**4. ¿El modelo de regresión no lineal funcionó mejor que el lineal? ¿Por qué?**\n","\n","El modelo de regresión no lineal no funcionó mejor que el lineal al comparar los resultados de su validación cruzada. El modelo lineal obtuvo un MSE de 18.14 y MAE de 3.12. El modelo no lineal un MSE de 23.86 y un MAE de 3.47. Cabe mencionar que hacer una comparación de R^2 no tendría sentido alguno ya que solo uno de los modelos es lineal.\n","\n","**5. ¿Notas alguna mejora con el árbol de decisión al agregar la variable categórica \"Status\"? ¿Por qué?**\n","\n","Sí noto una mejra con el árbol de decisión con la variable categórica \"Status\". Utilizar una variable categórica como variable predictora facilita la división de los datos. En este caso la variable categórica indica si un país está o no en desarrollo. En el mundo real esta información afecta un sinfin de métricas, incluyendo expectativa de vida.\n","\n","**6. ¿Se puede concluir algo interesante sobre los resultados de modelar estos datos con regresión? Argumenta tu respuesta.**\n","\n","Se puede concluir que sí es posible estimar la expectativa de vida de los habitantes de un país utilizando otras métricas. Dependiendo del tipo y número de variables de predicción se pueden crear modelos muy o no muy exactos. Este tipo de información es importante para la toma de decisiones de las economías globales ya que se pueden identificar algunas de las variables que más influyen en la expectativa de vida con el fin de hacer algo al respecto y con ello mejorar la calidad de vida de las personas."],"metadata":{"id":"GSc1xXaaV97R"}}],"metadata":{"colab":{"provenance":[{"file_id":"1_x76DZplpco62jrwbRJ8ZPrZWnvZbKbs","timestamp":1693480852697}],"mount_file_id":"1kbeDmHBvRB-1Q-3eHeWiPSYas8I-2v6J","authorship_tag":"ABX9TyNFmHVX7XTn828cTGHKXElV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}