{"cells":[{"cell_type":"markdown","metadata":{"id":"-zx999QwJzep"},"source":["<h1>Problemas de clasificación - Ejercicio 1</h1>\n","\n","A01639224 | Fausto Alejandro Palma Cervantes\n","\n","TC3006C.102 | Inteligencia artificial avanzada para la ciencia de datos I\n","\n","4 de septiembre de 2023"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4v4f0JDHVBJV","executionInfo":{"status":"ok","timestamp":1694132911492,"user_tz":360,"elapsed":1372,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}}},"outputs":[],"source":["# Importar librerías y módulos\n","import numpy as np\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.feature_selection import SelectKBest, f_classif, SequentialFeatureSelector, RFE"]},{"cell_type":"markdown","metadata":{"id":"BsoD_9W8KALm"},"source":["## Ejercicio 1\n","\n","**4 - P1_3.txt**\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":422,"status":"ok","timestamp":1694132928211,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"rXWHQlpkJYss","outputId":"62636627-7d2a-4ede-a19d-d48719078ea9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Observaciones: 1794\n","Variables: 153\n"]}],"source":["# Importar el conjunto de datos\n","cr_a = np.loadtxt('/content/drive/MyDrive/z. Aprendizaje/P1_3.txt')\n","print('Observaciones:', cr_a.shape[0])\n","print('Variables:', cr_a.shape[1] - 2)"]},{"cell_type":"markdown","source":["## 1. Determina si es necesario balancear los datos.\n","\n","En caso de que sea afirmativo, en todo este ejercicio tendrás que utilizar alguna estrategia para mitigar el problema de tener una muestra desbalanceada."],"metadata":{"id":"PPtmvM29JHY2"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1694132929965,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"gF_ZvcS-K6ta","outputId":"68041afb-e2bd-408c-85fd-1f3ead15e958"},"outputs":[{"output_type":"stream","name":"stdout","text":["Muestras clase 1: 298 (17%)\n","Muestras clase 2: 1496 (83%)\n"]}],"source":["# Cantidad de muestras en cada clase\n","class_1 = np.sum(cr_a[:, 0] == 1)\n","class_2 = np.sum(cr_a[:, 0] == 2)\n","\n","# Porcentaje de muestras en cada clase\n","p_class_1 = round(class_1 / len(cr_a) * 100)\n","p_class_2 = round(class_2 / len(cr_a) * 100)\n","\n","# Imprimir la proporción de clases\n","print(f'Muestras clase 1: {class_1} ({p_class_1}%)')\n","print(f'Muestras clase 2: {class_2} ({p_class_2}%)')"]},{"cell_type":"markdown","source":["Ya que la solo el 17% de la muestra pertenece a la clase 1 y el 83% pertenece a la clase 2, se puede concluir que se está trabajando con una muestra desbalanceada y por ende es necesario balancear los datos."],"metadata":{"id":"llT9KSVzIlIQ"}},{"cell_type":"markdown","source":["## 2. Evalúa al menos 5 modelos de clasificación distintos utilizando validación cruzada, y determina cuál de ellos es el más efectivo."],"metadata":{"id":"b9D_p3T2JNRv"}},{"cell_type":"code","source":["# Identificar variables de prueba y de respuesta\n","x = cr_a[:, 2:]\n","y = cr_a[:, 0]\n","\n","# Número de plieges\n","n_folds = 3\n","\n","# Dividir los conjuntos de prueba y entrenamiento\n","# (Considerando que la muestra está desbalanceada)\n","kf = StratifiedKFold(n_splits=n_folds, shuffle=True)"],"metadata":{"id":"uvfZmTg6_s5c","executionInfo":{"status":"ok","timestamp":1694132931878,"user_tz":360,"elapsed":169,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Linear SVM\n","print('Linear SVM')\n","\n","# Arreglo para evaluar el desempeño del modelo\n","cv_y_test = []\n","cv_y_pred = []\n","\n","# Repetir el proceso por cada pliege\n","for train_index, test_index in kf.split(x, y):\n","\n","    # Entrenar la regresión con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    clf = SVC(kernel='linear')\n","    clf.fit(x_train, y_train)\n","\n","    # Probar la regresión con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = clf.predict(x_test)\n","\n","    # Almacenar los valores verdaderos y predicciones\n","    cv_y_test.append(y_test)\n","    cv_y_pred.append(y_pred)\n","\n","# Evaluar el desempeño del modelo\n","print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdqEaiFb-v1k","executionInfo":{"status":"ok","timestamp":1694132934935,"user_tz":360,"elapsed":1337,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"24419ba9-0ac3-4d41-d6cc-42626e790db0"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Linear SVM\n","              precision    recall  f1-score   support\n","\n","         1.0       0.72      0.65      0.69       298\n","         2.0       0.93      0.95      0.94      1496\n","\n","    accuracy                           0.90      1794\n","   macro avg       0.83      0.80      0.81      1794\n","weighted avg       0.90      0.90      0.90      1794\n","\n"]}]},{"cell_type":"code","source":["# RBF SVM\n","print('RBF SVM')\n","\n","# Arreglo para evaluar el desempeño del modelo\n","cv_y_test = []\n","cv_y_pred = []\n","\n","# Repetir el proceso por cada pliege\n","for train_index, test_index in kf.split(x, y):\n","\n","    # Entrenar la regresión con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    clf = SVC(kernel='rbf')\n","    clf.fit(x_train, y_train)\n","\n","    # Probar la regresión con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = clf.predict(x_test)\n","\n","    # Almacenar los valores verdaderos y predicciones\n","    cv_y_test.append(y_test)\n","    cv_y_pred.append(y_pred)\n","\n","# Evaluar el desempeño del modelo\n","print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3Zsz8oa_yeT","executionInfo":{"status":"ok","timestamp":1694132936758,"user_tz":360,"elapsed":455,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"fa97b8aa-a908-41c2-dbae-d4003b05b1ef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["RBF SVM\n","              precision    recall  f1-score   support\n","\n","         1.0       0.85      0.55      0.67       298\n","         2.0       0.92      0.98      0.95      1496\n","\n","    accuracy                           0.91      1794\n","   macro avg       0.88      0.77      0.81      1794\n","weighted avg       0.91      0.91      0.90      1794\n","\n"]}]},{"cell_type":"code","source":["# K-NEAREST NEIGHBORS\n","print('K-NEAREST NEIGHBORS')\n","\n","# Arreglo para evaluar el desempeño del modelo\n","cv_y_test = []\n","cv_y_pred = []\n","\n","# Repetir el proceso por cada pliege\n","for train_index, test_index in kf.split(x, y):\n","\n","    # Entrenar la regresión con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    clf = KNeighborsClassifier(n_neighbors=3)\n","    clf.fit(x_train, y_train)\n","\n","    # Probar la regresión con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = clf.predict(x_test)\n","\n","    # Almacenar los valores verdaderos y predicciones\n","    cv_y_test.append(y_test)\n","    cv_y_pred.append(y_pred)\n","\n","# Evaluar el desempeño del modelo\n","print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"liNYrhRn_-Hr","executionInfo":{"status":"ok","timestamp":1694132938760,"user_tz":360,"elapsed":139,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"dc3171b7-ef3b-49d6-e070-5d6f84908151"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["K-NEAREST NEIGHBORS\n","              precision    recall  f1-score   support\n","\n","         1.0       0.60      0.34      0.43       298\n","         2.0       0.88      0.96      0.92      1496\n","\n","    accuracy                           0.85      1794\n","   macro avg       0.74      0.65      0.67      1794\n","weighted avg       0.83      0.85      0.84      1794\n","\n"]}]},{"cell_type":"code","source":["# DECISION TREE\n","print('DECISION TREE')\n","\n","# Arreglo para evaluar el desempeño del modelo\n","cv_y_test = []\n","cv_y_pred = []\n","\n","# Repetir el proceso por cada pliege\n","for train_index, test_index in kf.split(x, y):\n","\n","    # Entrenar la regresión con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    clf = DecisionTreeClassifier()\n","    clf.fit(x_train, y_train)\n","\n","    # Probar la regresión con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = clf.predict(x_test)\n","\n","    # Almacenar los valores verdaderos y predicciones\n","    cv_y_test.append(y_test)\n","    cv_y_pred.append(y_pred)\n","\n","# Evaluar el desempeño del modelo\n","print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9sCOXydAvAe","executionInfo":{"status":"ok","timestamp":1694132941919,"user_tz":360,"elapsed":733,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"016172ba-8940-4245-e9dd-ed0a7ef004a3"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["DECISION TREE\n","              precision    recall  f1-score   support\n","\n","         1.0       0.44      0.43      0.43       298\n","         2.0       0.89      0.89      0.89      1496\n","\n","    accuracy                           0.81      1794\n","   macro avg       0.66      0.66      0.66      1794\n","weighted avg       0.81      0.81      0.81      1794\n","\n"]}]},{"cell_type":"code","source":["# LINEAR DISCRIMINANT ANALYSIS\n","print('LINEAR DISCRIMINANT ANALYSIS')\n","\n","# Arreglo para evaluar el desempeño del modelo\n","cv_y_test = []\n","cv_y_pred = []\n","\n","# Repetir el proceso por cada pliege\n","for train_index, test_index in kf.split(x, y):\n","\n","    # Entrenar la regresión con el conjunto de entrenamiento\n","    x_train = x[train_index, :]\n","    y_train = y[train_index]\n","    clf = LinearDiscriminantAnalysis()\n","    clf.fit(x_train, y_train)\n","\n","    # Probar la regresión con el conjunto de prueba\n","    x_test = x[test_index, :]\n","    y_test = y[test_index]\n","    y_pred = clf.predict(x_test)\n","\n","    # Almacenar los valores verdaderos y predicciones\n","    cv_y_test.append(y_test)\n","    cv_y_pred.append(y_pred)\n","\n","# Evaluar el desempeño del modelo\n","print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhXSvPUfBFaT","executionInfo":{"status":"ok","timestamp":1694132944018,"user_tz":360,"elapsed":321,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"8c6471e9-ca51-4852-d9f8-091f52a7c25d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["LINEAR DISCRIMINANT ANALYSIS\n","              precision    recall  f1-score   support\n","\n","         1.0       0.70      0.64      0.67       298\n","         2.0       0.93      0.95      0.94      1496\n","\n","    accuracy                           0.89      1794\n","   macro avg       0.81      0.79      0.80      1794\n","weighted avg       0.89      0.89      0.89      1794\n","\n"]}]},{"cell_type":"markdown","source":["El modelo de clasificación SVM RBF es el más efectivo ya que en general genera los mejores resultados en el reporte de clasificación. El modelo SVM linear también es efectivo pero considerando los resultados específicamente de la clase 1 el kernel RBF es mejor."],"metadata":{"id":"HxkhUM-CnSuF"}},{"cell_type":"markdown","source":["## 3. Implementa desde cero el método de regresión logística, y evalúalo con el conjunto de datos."],"metadata":{"id":"zxNo9ty5N_Un"}},{"cell_type":"code","source":["# Crear arreglo de variables predictoras con columna de 1 para calcular la constante\n","X = np.column_stack((np.ones(x.shape[0]), x))\n","\n","# Función sigmoide logística\n","# (dónde se ubica en la S)\n","def sigmoid(z):\n","    return 1 / (1 + np.exp(-z))\n","\n","# Arreglo para guardar las betas\n","beta = np.zeros(X.shape[1])\n","\n","# Número de iteraciones de todos los datos (epoch)\n","for i in range(1000):\n","\n","    # Calcular probabilidades (predichas y estimadas)\n","    logits = np.dot(X, beta)\n","    y_pred = sigmoid(logits)\n","\n","    # Calcular gradiente de la función de costo\n","    gradient = np.dot(X.T, (y_pred - y)) / len(y)\n","\n","    # Actualizar los valores de las betas modelo (0.1 = tasa de aprendizaje)\n","    beta -= 0.1 * gradient\n","\n","# Impresión de resultados\n","print('Coeficientes del modelo:', beta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bOMcNJeKOCys","executionInfo":{"status":"ok","timestamp":1694132949790,"user_tz":360,"elapsed":411,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"5fdb9f38-58d1-4f8d-a0c5-dd9106073406"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Coeficientes del modelo: [ 9.01590635e+01 -7.68782787e+00 -1.53161020e+00  4.69294057e+00\n","  8.14594155e+00  8.08619584e+00  5.33197253e+00  1.27463567e+00\n"," -2.80486224e+00 -6.17570170e+00 -8.54060833e+00 -9.37090334e+00\n"," -7.82109928e+00 -3.77191489e+00  1.47453409e+00  6.02557710e+00\n","  8.56053785e+00  8.41238180e+00  5.58955763e+00  1.80434005e+00\n","  4.84381979e-01  3.71149105e+00  9.04934748e+00  1.12890844e+01\n","  8.05483324e+00  2.07107685e+00 -2.94294493e+00 -6.68115129e+00\n"," -1.06495247e+01 -1.37207577e+01 -1.24004537e+01 -5.84695597e+00\n","  1.98881939e+00  6.40949278e+00  6.42345810e+00  3.99363437e+00\n","  5.67448124e-01 -3.59081401e+00 -7.38779649e+00 -8.54886997e+00\n"," -5.94884097e+00 -1.15898588e+00  2.96615868e+00  4.70482706e+00\n","  4.10168770e+00  1.89056245e+00 -1.26782279e+00 -4.37687687e+00\n"," -5.80000836e+00 -4.19408087e+00  5.60628942e-02  4.72411588e+00\n","  1.82902903e+01  1.50679793e+01  2.64257248e+00 -1.30078882e+01\n"," -2.13387021e+01 -1.74513021e+01 -6.44987745e+00  3.32217639e+00\n","  8.88702539e+00  1.22131913e+01  1.34290908e+01  9.15015128e+00\n"," -1.21971723e+00 -1.13181284e+01 -1.34796510e+01 -7.29250346e+00\n","  7.44017590e-01  5.76854913e+00  9.04857613e+00  1.26129383e+01\n","  1.32499173e+01  5.95419230e+00 -7.59918392e+00 -1.83092164e+01\n"," -1.88708076e+01 -1.09733353e+01 -1.51248386e+00  5.76209114e+00\n","  1.14645388e+01  1.47426246e+01  1.13037985e+01 -3.06226970e-01\n"," -1.35243819e+01 -1.88026568e+01 -1.34308060e+01 -3.23950202e+00\n","  5.51025583e+00  1.22086123e+01  1.80139347e+01  1.94803766e+01\n","  1.11560208e+01 -5.31160834e+00 -1.92006575e+01 -2.07427300e+01\n"," -1.11160416e+01  5.20769915e-01  8.30680611e+00  1.36202787e+01\n","  1.77116485e+01  1.59498209e+01  3.86141019e+00 -2.93510879e+00\n"," -5.19111979e+00 -5.41184953e+00 -4.38872582e+00 -2.82259640e+00\n"," -5.01064978e-01  2.53795016e+00  4.81505557e+00  4.55880014e+00\n","  2.12850896e+00  9.50869029e-02  1.71127202e-01  1.06040571e+00\n","  6.90068166e-01 -1.41128027e-01  1.36450884e+00  5.17839204e+00\n","  7.04626953e+00  3.63278453e+00 -2.53078308e+00 -5.69857073e+00\n"," -3.96441696e+00 -1.10372027e+00 -9.29988142e-01 -2.31638654e+00\n"," -1.64723375e+00  1.37365558e+00  2.99373840e+00  5.31774290e-01\n"," -3.97947410e+00 -6.39156657e+00 -5.29545437e+00 -2.70065090e+00\n"," -5.49674056e-01  1.44119921e+00  3.84540641e+00  5.08569188e+00\n","  2.82110620e+00 -2.37311880e+00 -6.49480714e+00 -6.34642406e+00\n"," -3.18030427e+00 -7.12299324e-01 -9.80411050e-02  1.11332791e+00\n","  4.43006410e+00  7.05892763e+00  5.28022296e+00  5.23415348e-02\n"," -3.46335253e+00 -2.33094520e+00]\n"]}]},{"cell_type":"markdown","source":["## 4. Con alguno de los clasificadores que probaste en los pasos anteriores, determina el número óptimo de características utilizando un método tipo Filter."],"metadata":{"id":"YYuzsxehOEdO"}},{"cell_type":"code","source":["# Definir el número de características\n","n_feats = [i for i in range(1, 154)]\n","\n","# Arreglo para guardar los valores para cada número de características\n","acc_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    acc_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = StratifiedKFold(n_splits=3, shuffle=True)\n","\n","    # Repetir el proceso por cada pliege\n","    for train_index, test_index in kf.split(x, y):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        clf_cv = SVC(kernel='rbf')\n","        fselection_cv = SelectKBest(f_classif, k=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        clf_cv.fit(x_train, y_train)\n","\n","        # Probar el modelo con el conjunto de prueba\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = clf_cv.predict(x_test)\n","\n","        # Calcular la exactitud del modelo y añadir al arreglo\n","        acc_i = accuracy_score(y_test, y_pred)\n","        acc_cv.append(acc_i)\n","\n","    # Calcular la exactitud para cada número de características\n","    acc = np.average(acc_cv)\n","    acc_nfeat.append(acc)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, '| ACC:', acc)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmax(acc_nfeat)\n","opt_features = n_feats[opt_index]\n","print('Número óptimo de predictores:', opt_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsMJVQJCB-AJ","executionInfo":{"status":"ok","timestamp":1694132978816,"user_tz":360,"elapsed":26352,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"dc5d68e3-aaf7-4793-f12b-861db029c7bf"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["N: 1 | ACC: 0.838907469342252\n","N: 2 | ACC: 0.8394648829431439\n","N: 3 | ACC: 0.8489409141583054\n","N: 4 | ACC: 0.8534002229654404\n","N: 5 | ACC: 0.8617614269788184\n","N: 6 | ACC: 0.8645484949832776\n","N: 7 | ACC: 0.866778149386845\n","N: 8 | ACC: 0.8756967670011148\n","N: 9 | ACC: 0.8756967670011148\n","N: 10 | ACC: 0.8762541806020065\n","N: 11 | ACC: 0.8835005574136009\n","N: 12 | ACC: 0.8935340022296544\n","N: 13 | ACC: 0.8835005574136009\n","N: 14 | ACC: 0.8940914158305461\n","N: 15 | ACC: 0.8896321070234113\n","N: 16 | ACC: 0.8929765886287625\n","N: 17 | ACC: 0.8913043478260869\n","N: 18 | ACC: 0.8890746934225194\n","N: 19 | ACC: 0.890746934225195\n","N: 20 | ACC: 0.8918617614269788\n","N: 21 | ACC: 0.8957636566332218\n","N: 22 | ACC: 0.8952062430323299\n","N: 23 | ACC: 0.9002229654403567\n","N: 24 | ACC: 0.8974358974358974\n","N: 25 | ACC: 0.8985507246376812\n","N: 26 | ACC: 0.9035674470457078\n","N: 27 | ACC: 0.8968784838350055\n","N: 28 | ACC: 0.9041248606465997\n","N: 29 | ACC: 0.9013377926421405\n","N: 30 | ACC: 0.9024526198439241\n","N: 31 | ACC: 0.8991081382385729\n","N: 32 | ACC: 0.8996655518394648\n","N: 33 | ACC: 0.9018952062430322\n","N: 34 | ACC: 0.9013377926421405\n","N: 35 | ACC: 0.9041248606465997\n","N: 36 | ACC: 0.8935340022296544\n","N: 37 | ACC: 0.899108138238573\n","N: 38 | ACC: 0.9013377926421405\n","N: 39 | ACC: 0.9002229654403567\n","N: 40 | ACC: 0.907469342251951\n","N: 41 | ACC: 0.899108138238573\n","N: 42 | ACC: 0.8985507246376812\n","N: 43 | ACC: 0.8985507246376812\n","N: 44 | ACC: 0.9007803790412486\n","N: 45 | ACC: 0.8985507246376812\n","N: 46 | ACC: 0.8963210702341137\n","N: 47 | ACC: 0.8963210702341137\n","N: 48 | ACC: 0.9035674470457078\n","N: 49 | ACC: 0.9041248606465997\n","N: 50 | ACC: 0.9035674470457079\n","N: 51 | ACC: 0.9091415830546264\n","N: 52 | ACC: 0.9024526198439241\n","N: 53 | ACC: 0.9018952062430322\n","N: 54 | ACC: 0.9030100334448159\n","N: 55 | ACC: 0.9024526198439241\n","N: 56 | ACC: 0.8957636566332218\n","N: 57 | ACC: 0.9085841694537345\n","N: 58 | ACC: 0.9018952062430322\n","N: 59 | ACC: 0.9096989966555183\n","N: 60 | ACC: 0.9035674470457078\n","N: 61 | ACC: 0.907469342251951\n","N: 62 | ACC: 0.9069119286510591\n","N: 63 | ACC: 0.9046822742474916\n","N: 64 | ACC: 0.9091415830546264\n","N: 65 | ACC: 0.9102564102564102\n","N: 66 | ACC: 0.9102564102564102\n","N: 67 | ACC: 0.9113712374581939\n","N: 68 | ACC: 0.9085841694537345\n","N: 69 | ACC: 0.9069119286510591\n","N: 70 | ACC: 0.907469342251951\n","N: 71 | ACC: 0.9085841694537345\n","N: 72 | ACC: 0.9091415830546264\n","N: 73 | ACC: 0.9108138238573021\n","N: 74 | ACC: 0.9124860646599776\n","N: 75 | ACC: 0.9108138238573021\n","N: 76 | ACC: 0.9136008918617614\n","N: 77 | ACC: 0.9141583054626533\n","N: 78 | ACC: 0.9080267558528426\n","N: 79 | ACC: 0.9119286510590857\n","N: 80 | ACC: 0.9108138238573021\n","N: 81 | ACC: 0.9136008918617614\n","N: 82 | ACC: 0.9052396878483835\n","N: 83 | ACC: 0.9063545150501672\n","N: 84 | ACC: 0.9119286510590858\n","N: 85 | ACC: 0.9113712374581939\n","N: 86 | ACC: 0.9102564102564102\n","N: 87 | ACC: 0.9124860646599776\n","N: 88 | ACC: 0.9147157190635452\n","N: 89 | ACC: 0.9130434782608696\n","N: 90 | ACC: 0.9208472686733556\n","N: 91 | ACC: 0.9130434782608695\n","N: 92 | ACC: 0.9147157190635452\n","N: 93 | ACC: 0.9141583054626533\n","N: 94 | ACC: 0.9130434782608695\n","N: 95 | ACC: 0.9136008918617614\n","N: 96 | ACC: 0.9119286510590858\n","N: 97 | ACC: 0.9124860646599776\n","N: 98 | ACC: 0.9152731326644371\n","N: 99 | ACC: 0.9175027870680044\n","N: 100 | ACC: 0.9080267558528429\n","N: 101 | ACC: 0.9091415830546264\n","N: 102 | ACC: 0.9119286510590858\n","N: 103 | ACC: 0.9096989966555183\n","N: 104 | ACC: 0.9102564102564102\n","N: 105 | ACC: 0.9175027870680044\n","N: 106 | ACC: 0.9147157190635452\n","N: 107 | ACC: 0.9119286510590858\n","N: 108 | ACC: 0.9136008918617614\n","N: 109 | ACC: 0.9141583054626533\n","N: 110 | ACC: 0.9147157190635452\n","N: 111 | ACC: 0.9136008918617614\n","N: 112 | ACC: 0.9136008918617614\n","N: 113 | ACC: 0.9152731326644371\n","N: 114 | ACC: 0.9119286510590858\n","N: 115 | ACC: 0.9096989966555183\n","N: 116 | ACC: 0.9102564102564102\n","N: 117 | ACC: 0.9163879598662207\n","N: 118 | ACC: 0.9091415830546264\n","N: 119 | ACC: 0.9130434782608695\n","N: 120 | ACC: 0.910813823857302\n","N: 121 | ACC: 0.910813823857302\n","N: 122 | ACC: 0.910813823857302\n","N: 123 | ACC: 0.9152731326644371\n","N: 124 | ACC: 0.9158305462653288\n","N: 125 | ACC: 0.9069119286510591\n","N: 126 | ACC: 0.9113712374581939\n","N: 127 | ACC: 0.9158305462653288\n","N: 128 | ACC: 0.9163879598662207\n","N: 129 | ACC: 0.9119286510590858\n","N: 130 | ACC: 0.9096989966555183\n","N: 131 | ACC: 0.9136008918617614\n","N: 132 | ACC: 0.9141583054626533\n","N: 133 | ACC: 0.9124860646599776\n","N: 134 | ACC: 0.9102564102564102\n","N: 135 | ACC: 0.910813823857302\n","N: 136 | ACC: 0.9130434782608695\n","N: 137 | ACC: 0.9141583054626533\n","N: 138 | ACC: 0.9130434782608695\n","N: 139 | ACC: 0.9169453734671126\n","N: 140 | ACC: 0.9158305462653288\n","N: 141 | ACC: 0.9152731326644371\n","N: 142 | ACC: 0.9186176142697882\n","N: 143 | ACC: 0.9191750278706801\n","N: 144 | ACC: 0.9069119286510591\n","N: 145 | ACC: 0.9119286510590858\n","N: 146 | ACC: 0.919732441471572\n","N: 147 | ACC: 0.9136008918617614\n","N: 148 | ACC: 0.9124860646599777\n","N: 149 | ACC: 0.9102564102564101\n","N: 150 | ACC: 0.9180602006688963\n","N: 151 | ACC: 0.9119286510590858\n","N: 152 | ACC: 0.9069119286510591\n","N: 153 | ACC: 0.9147157190635452\n","Número óptimo de predictores: 90\n"]}]},{"cell_type":"markdown","source":["## 5. Repite el paso anterior, pero para un método de selección de características de tipo Wrapper.\n","\n"],"metadata":{"id":"x36W3rvuOL0T"}},{"cell_type":"markdown","source":["Pese a varios intentos, no se pudo ejecutar completo el método de selección de características de tipo Wrapper para este conjunto de datos."],"metadata":{"id":"2h0WfDoqpOD3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"vIJOoqIJaPR_"},"outputs":[],"source":["# Definir el número de características\n","n_feats = [i for i in range(1, 153)]\n","\n","# Arreglo para guardar los valores para cada número de características\n","acc_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    acc_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = StratifiedKFold(n_splits=3, shuffle=True)\n","\n","    # Repetir el proceso por cada pliege\n","    for train_index, test_index in kf.split(x, y):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        clf_cv = SVC(kernel='rbf')\n","        fselection_cv = SequentialFeatureSelector(clf_cv, n_features_to_select=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        clf_cv.fit(x_train, y_train)\n","\n","        # Probar el modelo con el conjunto de prueba\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = clf_cv.predict(x_test)\n","\n","        # Calcular la exactitud del modelo y añadir al arreglo\n","        acc_i = accuracy_score(y_test, y_pred)\n","        acc_cv.append(acc_i)\n","\n","    # Calcular la exactitud para cada número de características\n","    acc = np.average(acc_cv)\n","    acc_nfeat.append(acc)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, '| ACC:', acc)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmax(acc_nfeat)\n","opt_features = n_feats[opt_index]\n","print('Número óptimo de predictores: ', opt_features)"]},{"cell_type":"markdown","source":["## 6. Repite el paso 4, pero para un método de selección de características de tipo Filter-Wrapper."],"metadata":{"id":"bH7x3ZqoOQeg"}},{"cell_type":"markdown","source":["Pese a varios intentos, no se pudo ejecutar completo el método de selección de características de tipo Filter-Wrapper para este conjunto de datos. En comparación a los pasos anteriores, para el paso 6 se utilizó el kernel 'linear' del model SVC y no 'rbf'. Al producir este último un modelo no lineal, no tiene atributos 'coef_' ni 'feature\\_importances\\_attribute', los cuales son necesarios para la selección de características con la función RFE."],"metadata":{"id":"pspppNPeQ4dO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ll7gOsefcNni"},"outputs":[],"source":["# Definir el número de características\n","n_feats = [i for i in range(1, 154)]\n","\n","# Arreglo para guardar los valores para cada número de características\n","acc_nfeat = []\n","\n","# Repetir el proceso por cada característica\n","for n_feat in n_feats:\n","\n","    # Arreglo para guardar los valores de las pruebas\n","    acc_cv = []\n","\n","    # Dividir los conjuntos de prueba y entrenamiento\n","    kf = StratifiedKFold(n_splits=3, shuffle=True)\n","\n","    # Repetir el proceso por cada pliege\n","    for train_index, test_index in kf.split(x, y):\n","\n","        # Seleccionar el número óptimo de predictores\n","        x_train = x[train_index, :]\n","        y_train = y[train_index]\n","        clf_cv = SVC(kernel='linear')\n","        fselection_cv = RFE(clf_cv, n_features_to_select=n_feat)\n","\n","        # Seleccionar los predictores óptimos\n","        fselection_cv.fit(x_train, y_train)\n","\n","        # Calcular un modelo con los predictores óptimos\n","        x_train = fselection_cv.transform(x_train)\n","        clf_cv.fit(x_train, y_train)\n","\n","        # Probar el modelo con el conjunto de prueba\n","        x_test = fselection_cv.transform(x[test_index, :])\n","        y_test = y[test_index]\n","        y_pred = clf_cv.predict(x_test)\n","\n","        # Calcular la exactitud del modelo y añadir al arreglo\n","        acc_i = accuracy_score(y_test, y_pred)\n","        acc_cv.append(acc_i)\n","\n","    # Calcular la exactitud para cada número de características\n","    acc = np.average(acc_cv)\n","    acc_nfeat.append(acc)\n","\n","    # Imprimir el resultado de las pruebas de cada número de características\n","    print('N:', n_feat, '| ACC:', acc)\n","\n","# Imprimir el número óptimo de predictores\n","opt_index = np.argmax(acc_nfeat)\n","opt_features = n_feats[opt_index]\n","print('Número óptimo de predictores: ', opt_features)"]},{"cell_type":"markdown","source":["## 7. Escoge alguna de las técnicas de selección de características que probaste con anteioridad, y con el número óptimo de características encontrado, prepara tu modelo para producción haciendo lo siguiente:\n","\n","### A. Aplica el método de selección de características con todos los datos.\n","\n","### B. Ajusta el modelo con las características encontradas."],"metadata":{"id":"o0UlDFr7OTMg"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":168,"status":"ok","timestamp":1694132987935,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"},"user_tz":360},"id":"8paYpp0V3kvm","outputId":"90186c2f-06b3-46f3-bd5e-d25669c64b4c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Predictores óptimos: ['x2' 'x3' 'x9' 'x10' 'x11' 'x12' 'x13' 'x15' 'x16' 'x17' 'x18' 'x19'\n"," 'x20' 'x21' 'x22' 'x24' 'x25' 'x26' 'x27' 'x28' 'x29' 'x30' 'x31' 'x38'\n"," 'x39' 'x41' 'x42' 'x43' 'x44' 'x49' 'x50' 'x55' 'x60' 'x61' 'x62' 'x63'\n"," 'x64' 'x65' 'x66' 'x67' 'x69' 'x70' 'x71' 'x75' 'x76' 'x77' 'x78' 'x79'\n"," 'x80' 'x88' 'x89' 'x90' 'x91' 'x93' 'x95' 'x96' 'x97' 'x98' 'x99' 'x100'\n"," 'x101' 'x102' 'x103' 'x104' 'x105' 'x106' 'x111' 'x112' 'x113' 'x114'\n"," 'x115' 'x117' 'x118' 'x119' 'x127' 'x128' 'x129' 'x130' 'x131' 'x132'\n"," 'x133' 'x134' 'x139' 'x140' 'x141' 'x142' 'x147' 'x148' 'x149' 'x150']\n"]}],"source":["# SVM RBF - FILTER\n","\n","# Seleccionar los predictores óptimos\n","clf = SVC(kernel = 'rbf')\n","fselection = SelectKBest(f_classif, k=opt_features)\n","fselection.fit(x, y)\n","print('Predictores óptimos:', fselection.get_feature_names_out())"]},{"cell_type":"code","source":["# Ajustar el modelo con los predictores óptimos\n","x_transformed = fselection.transform(x)\n","clf.fit(x_transformed, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"c2d5_SIRqI3B","executionInfo":{"status":"ok","timestamp":1694132990166,"user_tz":360,"elapsed":170,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"85c3bc07-ee43-4c47-c444-6cba85195262"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC()"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"j87bI-s5d0Ua"},"source":["## 8. Contesta las siguientes preguntas:\n","\n","**A. ¿Qué pasa si no se considera el problema de tener datos desbalanceados para este caso? ¿Por qué?**\n","\n","No considerar que se tienen datos desbalanceados causaría que al momento de hacer la división en conjuntos de prueba y entrenamiento se limitara la exactitud del modelo para las clases con menos datos debido a la falta de valores de entrenamiento.\n","\n","**B. De todos los clasificadores, ¿cuál o cuales consideras que son adecuados para los datos? ¿Qué propiedades tienen dichos modelos que los hacen apropiados para los datos? Argumenta tu respuesta.**\n","\n","Los clasificadores SVM parecen producir mejores resultados en todos los rubros individuales de los reportes de clasificación. Ya que el impacto que los valores atípicos tienen en este tipo de clasificadores es limitado, que este tipo de modelos funcionan bien con altos números de características y que la regularización incorporada previene el sobreajuste, estos modelos son apropiados para este tipo de datos.\n","\n","**C. ¿Es posibles reducir la dimensionalidad del problema sin perder rendimiento en el modelo? ¿Por qué?**\n","\n","En base a los procedimientos que se ejecutaron para encontrar el número óptimo de clasificadores, sí es posible reducir la dimensionalidad del problema sin perder rendimiento en el modelo. Al ver los valores de exactitud que se imprimieron para cada número de dimensiones, se puede ver que dicha se estanca al acercarse a los 153 valores. Es por ello que no se puede concluir que sin reducir la dimensionalidad se produce un modelo con mejor rendimiento.\n","\n","**D. ¿Qué método de selección de características consideras el más adecuado para este caso? ¿Por qué?**\n","\n","Dado que de los cinco modelos de clasificación el modelo SVM con kernel RBF produjo los mejores resultados, creo que el método de selección de características Filter es el más adecuado para el caso. Mientras que el método Filter-Wrapper queda automáticamente descalificado al no poder utilizarse en modelos no lineales, la complejidad computacional del método Wrapper y la naturaleza de los datos hacen que el método Filter sea el más adecuado y efectivo para esta actividad.\n","\n","**E. Si quisieras mejorar el rendimiento de tus modelos, ¿qué más se podría hacer?**\n","\n","Previo a las pruebas de los distintos clasificadores, se calculó la correlación estadística entre las variables predictoras para determinar si la estandarización de los datos era necesaria. Ya que no se produjeron correlaciones mayores a 0.95, este procedimiento no mejoraría el rendimiento del modelo. Al ver que los datos de la primera clase únicamente conforman el 17% de todo el conjunto de datos y que la predicción de esta clase fue más baja en todos los modelos, tener más datos pertenecientes a esta clase podría mejorar la exactitud del modelo. Probar más clasificadores también podría resultar en el hallazgo de un mejor modelo.\n"]},{"cell_type":"code","source":["!apt-get install -y texlive-xetex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xTQ9VF2MgdT","executionInfo":{"status":"ok","timestamp":1694133073088,"user_tz":360,"elapsed":1472,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}},"outputId":"3ea0a642-882a-489c-f5b8-982011983c7e"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","texlive-xetex is already the newest version (2021.20220204-1).\n","0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n"]}]},{"cell_type":"code","source":["!jupyter nbconvert --to pdf '/content/drive/MyDrive/z. Aprendizaje/A01639224_ProblemasDeClasificacion_E1.ipynb' --output-dir='/content/drive/MyDrive/z. Aprendizaje'\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V04DrdA6lpf9","outputId":"c433524c-4b0e-4116-b102-0b995a5ff291","executionInfo":{"status":"ok","timestamp":1694133160528,"user_tz":360,"elapsed":8492,"user":{"displayName":"Fausto Alejandro Palma Cervantes","userId":"03206011748036634151"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook /content/drive/MyDrive/z. Aprendizaje/A01639224_ProblemasDeClasificacion_E1.ipynb to pdf\n","[NbConvertApp] Writing 72648 bytes to notebook.tex\n","[NbConvertApp] Building PDF\n","[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n","[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n","[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n","[NbConvertApp] PDF successfully created\n","[NbConvertApp] Writing 85904 bytes to /content/drive/MyDrive/z. Aprendizaje/A01639224_ProblemasDeClasificacion_E1.pdf\n"]}]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"18l8v5K-DtvGj5ASdSHMj_Wgjup8hhjq8","authorship_tag":"ABX9TyNxztWqGZ11uNVkdUD143fB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}